import os
import time
import json
import requests
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException

# ğŸ“‚ ì €ì¥ ê²½ë¡œ
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PDF_DIR = os.path.join(SCRIPT_DIR, "pdf_files")
JSON_FILE = os.path.join(SCRIPT_DIR, "hana_products_with_pdf.json")
os.makedirs(PDF_DIR, exist_ok=True)

# ğŸ“Œ ì´ì „ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (ì¬ì‹œì‘)
if os.path.exists(JSON_FILE):
    with open(JSON_FILE, "r", encoding="utf-8") as f:
        results = json.load(f)
else:
    results = []

# ì´ë¯¸ í¬ë¡¤ë§í•œ ìƒí’ˆëª… ë¦¬ìŠ¤íŠ¸
crawled_names = {item.get("ìƒí’ˆëª…") for item in results}

# ğŸ“Œ í¬ë¡¬ ë“œë¼ì´ë²„ ì˜µì…˜
options = webdriver.ChromeOptions()
# options.add_argument("--headless") # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ
options.add_argument("--start-maximized")
options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36")
driver = webdriver.Chrome(options=options)
wait = WebDriverWait(driver, 15)

# ğŸ“Œ ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ ê·¸ë£¹
list_pages = [
    "https://www.kebhana.com/cont/mall/mall09/mall0902/mall090201/index.jsp",
    "https://www.kebhana.com/cont/mall/mall09/mall0902/mall090202/index.jsp",
    "https://www.kebhana.com/cont/mall/mall09/mall0902/mall090203/index.jsp",
    "https://www.kebhana.com/cont/mall/mall09/mall0902/mall090204/index.jsp",
    "https://www.kebhana.com/cont/mall/mall09/mall0903/mall090301/index.jsp",
    "https://www.kebhana.com/cont/mall/mall09/mall0903/mall090302/index.jsp",
    "https://www.kebhana.com/cont/mall/mall09/mall0903/mall090303/index.jsp",
    "https://www.kebhana.com/cont/mall/mall09/mall0903/mall090304/index.jsp",
    "https://www.kebhana.com/cont/mall/mall09/mall0903/mall090305/index.jsp",
    "https://www.kebhana.com/cont/mall/mall09/mall0903/mall090306/index.jsp",
    "https://www.kebhana.com/cont/mall/mall09/mall0903/mall090307/index.jsp"
]

# ğŸ“Œ ê° ì¹´í…Œê³ ë¦¬ í˜ì´ì§€ ìˆœíšŒ
for list_url in list_pages:
    print(f"--- ì¹´í…Œê³ ë¦¬ ì‹œì‘: {list_url} ---")
    driver.get(list_url)
    time.sleep(2)

    # ğŸ“Œ ì‹ ê·œê°€ëŠ¥ìƒí’ˆê³¼ íŒë§¤ì¤‘ì§€ ìƒí’ˆ ëª¨ë‘ í¬ë¡¤ë§
    product_types = [
        {"name": "ì‹ ê·œê°€ëŠ¥ìƒí’ˆ", "click_needed": False},  # ê¸°ë³¸ ì„ íƒ
        {"name": "ì‹ ê·œì¤‘ì§€ìƒí’ˆ", "click_needed": True}        # í´ë¦­ í•„ìš”
    ]
    
    for product_type in product_types:
        print(f"\n=== {product_type['name']} ì²˜ë¦¬ ì‹œì‘ ===")
        
        if product_type['click_needed']:
            try:
                # íŒë§¤ì¤‘ì§€ ë¼ë””ì˜¤ ë²„íŠ¼ í´ë¦­
                discontinued_radio = wait.until(EC.element_to_be_clickable((By.XPATH, "//input[@type='radio' and @value='N']")))
                discontinued_radio.click()
                time.sleep(2)
                print(f"  - {product_type['name']} ì„ íƒ ì™„ë£Œ")
            except Exception as e:
                print(f"  - {product_type['name']} ì„ íƒ ì‹¤íŒ¨: {e}")
                continue
        
        page_count = 1
        max_retries_per_page = 3  # ê°™ì€ í˜ì´ì§€ì—ì„œ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        current_retry_count = 0
        last_processed_url = ""
        
        while True:  # í˜ì´ì§€ë„¤ì´ì…˜ ë°˜ë³µ
            current_url = driver.current_url
            print(f"[{product_type['name']}] í˜„ì¬ URL: {current_url}, í˜ì´ì§€: {page_count}")
            
            # ê°™ì€ URLì—ì„œ ë°˜ë³µë˜ëŠ” ê²½ìš° ì²´í¬
            if current_url == last_processed_url:
                current_retry_count += 1
                print(f"[ê²½ê³ ] ê°™ì€ í˜ì´ì§€ê°€ ë°˜ë³µë©ë‹ˆë‹¤. ì¬ì‹œë„ íšŸìˆ˜: {current_retry_count}/{max_retries_per_page}")
                if current_retry_count >= max_retries_per_page:
                    print("[ì—ëŸ¬] ê°™ì€ í˜ì´ì§€ì—ì„œ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. ë‹¤ìŒìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
                    break
            else:
                current_retry_count = 0
                last_processed_url = current_url
            
            try:
                # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°
                wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "td:nth-child(1) a")))
                product_links = driver.find_elements(By.CSS_SELECTOR, "td:nth-child(1) a")
                
                successful_crawls = 0  # í˜„ì¬ í˜ì´ì§€ì—ì„œ ì„±ê³µí•œ í¬ë¡¤ë§ ìˆ˜
                error_occurred = False  # í˜„ì¬ í˜ì´ì§€ì—ì„œ ì—ëŸ¬ ë°œìƒ ì—¬ë¶€
                
                for i in range(len(product_links)):
                    try:
                        # StaleElementReferenceException ë°©ì§€
                        product_links = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "td:nth-child(1) a")))
                        link = product_links[i]
                        product_name = link.text.strip()
                        
                        if not product_name:
                            continue

                        # ìƒí’ˆëª…ì— íŒë§¤ì¤‘ì§€ ì—¬ë¶€ í‘œì‹œ ì¶”ê°€
                        if product_type['name'] == "íŒë§¤ì¤‘ì§€":
                            product_name_with_status = f"{product_name}(íŒë§¤ì¤‘ë‹¨)"
                        else:
                            product_name_with_status = product_name

                        # ì´ë¯¸ ì €ì¥ëœ ìƒí’ˆì´ë©´ ê±´ë„ˆë›°ê¸°
                        if product_name_with_status in crawled_names:
                            print(f"[ìŠ¤í‚µ] '{product_name_with_status}' (ì´ë¯¸ í¬ë¡¤ë§ ì™„ë£Œ)")
                            continue

                        print(f"  > ìƒí’ˆ í¬ë¡¤ë§ ì‹œì‘: '{product_name_with_status}'")
                        
                        # ìƒí’ˆ ë§í¬ í´ë¦­
                        link.click()
                        
                        try:
                            # ìƒí’ˆ ìƒì„¸ í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°
                            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "dl.prodcutInfo")))
                            
                            detail_data = {"ìƒí’ˆëª…": product_name_with_status}

                            # ğŸ“Œ dtâ€“dd ìŒ ì¶”ì¶œ
                            try:
                                dts = driver.find_elements(By.CSS_SELECTOR, "dl.prodcutInfo dt")
                                dds = driver.find_elements(By.CSS_SELECTOR, "dl.prodcutInfo dd")
                                if dts and dds:
                                    for dt, dd in zip(dts, dds):
                                        dt_text = dt.text.strip()
                                        dd_text = dd.text.strip()
                                        if dt_text and dd_text:
                                            detail_data[dt_text] = dd_text
                            except Exception as e:
                                print(f"[ì—ëŸ¬] '{product_name_with_status}' dtâ€“dd ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                                
                            # ğŸ“Œ ê¸ˆë¦¬í‘œ ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)
                            rate_table_data = []
                            try:
                                # ëª¨ë“  í…Œì´ë¸”ì„ ì°¾ì•„ì„œ ê¸ˆë¦¬ ê´€ë ¨ í…Œì´ë¸” ì‹ë³„
                                tables = driver.find_elements(By.CSS_SELECTOR, "table")
                                for table in tables:
                                    try:
                                        # í—¤ë” ì°¾ê¸°
                                        headers = []
                                        header_elements = table.find_elements(By.CSS_SELECTOR, "thead th")
                                        if not header_elements:
                                            # theadê°€ ì—†ëŠ” ê²½ìš° ì²« ë²ˆì§¸ trì—ì„œ th ì°¾ê¸°
                                            first_row = table.find_element(By.CSS_SELECTOR, "tr")
                                            header_elements = first_row.find_elements(By.TAG_NAME, "th")
                                        
                                        headers = [th.text.strip() for th in header_elements]
                                        
                                        # ê¸ˆë¦¬ ê´€ë ¨ í…Œì´ë¸”ì¸ì§€ í™•ì¸
                                        is_rate_table = any(keyword in " ".join(headers).lower() 
                                                          for keyword in ["ê¸°ê°„", "ê¸ˆë¦¬", "ì—°ìœ¨", "ì´ìœ¨", "rate"])
                                        
                                        if is_rate_table and headers:
                                            print(f"    -> ê¸ˆë¦¬ í…Œì´ë¸” ë°œê²¬: {headers}")
                                            
                                            # ë°ì´í„° í–‰ ì¶”ì¶œ
                                            rows = table.find_elements(By.CSS_SELECTOR, "tbody tr")
                                            if not rows:
                                                # tbodyê°€ ì—†ëŠ” ê²½ìš° ëª¨ë“  trì—ì„œ tdê°€ ìˆëŠ” í–‰ë§Œ ì„ íƒ
                                                all_rows = table.find_elements(By.CSS_SELECTOR, "tr")
                                                rows = [row for row in all_rows if row.find_elements(By.TAG_NAME, "td")]
                                            
                                            for row in rows:
                                                cells = row.find_elements(By.TAG_NAME, "td")
                                                if len(cells) >= 2:  # ìµœì†Œ 2ê°œ ì…€ì´ ìˆì–´ì•¼ í•¨
                                                    cell_texts = [td.text.strip() for td in cells]
                                                    print(f"    -> í–‰ ë°ì´í„°: {cell_texts}")
                                                    
                                                    # ê¸°ê°„ê³¼ ê¸ˆë¦¬ ì •ë³´ê°€ ìˆëŠ” í–‰ë§Œ ì¶”ê°€
                                                    period = cell_texts[0] if len(cell_texts) > 0 else ""
                                                    rate = ""
                                                    
                                                    # ê¸ˆë¦¬ê°€ í¬í•¨ëœ ì…€ ì°¾ê¸°
                                                    for cell_text in cell_texts[1:]:
                                                        if '%' in cell_text and any(c.isdigit() for c in cell_text):
                                                            rate = cell_text
                                                            break
                                                    
                                                    if period and rate:
                                                        rate_info = {"ê¸°ê°„": period, "ê¸ˆë¦¬": rate}
                                                        # ì¶”ê°€ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ í¬í•¨
                                                        for i, header in enumerate(headers[2:], 2):
                                                            if i < len(cell_texts):
                                                                rate_info[header] = cell_texts[i]
                                                        rate_table_data.append(rate_info)
                                    except Exception as e:
                                        continue  # ì´ í…Œì´ë¸”ì€ ê±´ë„ˆë›°ê³  ë‹¤ìŒ í…Œì´ë¸” ì‹œë„
                                        
                            except Exception as e:
                                print(f"  > ê¸ˆë¦¬í‘œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
                                
                            detail_data["ê¸ˆë¦¬í‘œ"] = rate_table_data
                            if rate_table_data:
                                print(f"  > ê¸ˆë¦¬í‘œ ì¶”ì¶œ ì™„ë£Œ: {len(rate_table_data)}ê°œ í•­ëª©")
                            
                            # ğŸ“Œ ìƒí’ˆì„¤ëª…ì„œ PDF ë‹¤ìš´ë¡œë“œ
                            pdf_path = ""
                            try:
                                pdf_link_element = driver.find_element(By.LINK_TEXT, "ìƒí’ˆì„¤ëª…ì„œ")
                                link1 = pdf_link_element.get_attribute("href")
                                if link1:
                                    pdf_data = requests.get(link1).content
                                    pdf_filename = f"{product_name_with_status.replace('/', '_').replace(':', '')}.pdf"
                                    pdf_path = os.path.join(PDF_DIR, pdf_filename)
                                    with open(pdf_path, "wb") as f:
                                        f.write(pdf_data)
                                    print(f"  > PDF ì €ì¥ ì™„ë£Œ: {pdf_path}")
                            except NoSuchElementException:
                                print(f"  > '{product_name_with_status}' ìƒí’ˆì„¤ëª…ì„œ ë§í¬ ì—†ìŒ")
                            except Exception as e:
                                print(f"  > [ì—ëŸ¬] '{product_name_with_status}' PDF ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                            
                            detail_data["ìƒí’ˆì„¤ëª…ì„œ_ê²½ë¡œ"] = pdf_path

                            # ğŸ“Œ ë°ì´í„° ì €ì¥
                            results.append(detail_data)
                            crawled_names.add(product_name_with_status)
                            successful_crawls += 1
                            
                            # ì¦‰ì‹œ JSON ì €ì¥ (ì¤‘ê°„ ì €ì¥)
                            with open(JSON_FILE, "w", encoding="utf-8") as f:
                                json.dump(results, f, ensure_ascii=False, indent=2)

                            print(f"  > ë°ì´í„° ì €ì¥ ì™„ë£Œ: '{product_name_with_status}'")
                            
                        except TimeoutException:
                            print(f"[ì—ëŸ¬] '{product_name_with_status}' ìƒì„¸ í˜ì´ì§€ ë¡œë“œ ì‹œê°„ ì´ˆê³¼. ë‹¤ìŒ ìƒí’ˆìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
                            error_occurred = True
                            # íƒ€ì„ì•„ì›ƒ ë°œìƒí•œ ìƒí’ˆì„ í¬ë¡¤ë§ ì™„ë£Œ ëª©ë¡ì— ì¶”ê°€í•˜ì—¬ ì¬ì‹œë„ ë°©ì§€
                            crawled_names.add(product_name_with_status)
                        except Exception as e:
                            print(f"[ì—ëŸ¬] '{product_name_with_status}' í¬ë¡¤ë§ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
                            error_occurred = True
                            # ì—ëŸ¬ ë°œìƒí•œ ìƒí’ˆì„ í¬ë¡¤ë§ ì™„ë£Œ ëª©ë¡ì— ì¶”ê°€í•˜ì—¬ ì¬ì‹œë„ ë°©ì§€
                            crawled_names.add(product_name_with_status)
                        finally:
                            driver.back()
                            wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "td:nth-child(1) a")))
                            time.sleep(1) # í˜ì´ì§€ ë¦¬ë¡œë“œ ì•ˆì •í™” ëŒ€ê¸°
                    
                    except StaleElementReferenceException:
                        print("[ê²½ê³ ] StaleElementReferenceException ë°œìƒ. í˜ì´ì§€ë¥¼ ë‹¤ì‹œ ë¡œë“œí•˜ê³  ì¬ì‹œë„í•©ë‹ˆë‹¤.")
                        break # for ë£¨í”„ë¥¼ ë¹ ì ¸ë‚˜ì™€ while ë£¨í”„ì˜ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°
                    except Exception as e:
                        print(f"[ì—ëŸ¬] ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        continue

            except TimeoutException:
                print("[ì—ëŸ¬] ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ ë¡œë“œ ì‹œê°„ ì´ˆê³¼. ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
                break
            
            # ğŸ“Œ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
            try:
                # í˜„ì¬ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì •í™•íˆ í™•ì¸
                actual_current_page = page_count  # ê¸°ë³¸ê°’
                
                try:
                    # ì‹¤ì œ ì›¹í˜ì´ì§€ì—ì„œ í˜„ì¬ í™œì„±í™”ëœ í˜ì´ì§€ ë²ˆí˜¸ ê°€ì ¸ì˜¤ê¸°
                    current_page_element = driver.find_element(By.CSS_SELECTOR, "a.on")
                    actual_current_page = int(current_page_element.text.strip())
                    print(f"    - ì›¹í˜ì´ì§€ ì‹¤ì œ í˜„ì¬ í˜ì´ì§€: {actual_current_page}")
                    
                    # ì¶”ì  ì¤‘ì¸ í˜ì´ì§€ì™€ ì‹¤ì œ í˜ì´ì§€ê°€ ë‹¤ë¥´ë©´ ë™ê¸°í™”
                    if actual_current_page != page_count:
                        print(f"    - í˜ì´ì§€ ë²ˆí˜¸ ë™ê¸°í™”: {page_count} â†’ {actual_current_page}")
                        page_count = actual_current_page
                        
                except (NoSuchElementException, ValueError):
                    print(f"    - í˜„ì¬ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ. ì¶”ì  ì¤‘ì¸ í˜ì´ì§€ ì‚¬ìš©: {page_count}")

                # ì—ëŸ¬ê°€ ë°œìƒí–ˆê±°ë‚˜ ëª¨ë“  ìƒí’ˆì´ ì´ë¯¸ í¬ë¡¤ë§ë˜ì—ˆìœ¼ë©´ ê°•ì œë¡œ ë‹¤ìŒ í˜ì´ì§€ë¡œ
                if error_occurred or successful_crawls == 0:
                    print(f"    - ì—ëŸ¬ ë°œìƒ ë˜ëŠ” ìƒˆë¡œìš´ í¬ë¡¤ë§ ì—†ìŒ. ë‹¤ìŒ í˜ì´ì§€ë¡œ ê°•ì œ ì´ë™")
                    next_page = actual_current_page + 1
                else:
                    next_page = actual_current_page + 1

                # ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì°¾ê¸° ë° í´ë¦­
                next_page_xpath = f"//div[@class='paging']//a[normalize-space(text())='{next_page}' and not(@class='on')]"
                
                try:
                    next_page_btn = wait.until(EC.element_to_be_clickable((By.XPATH, next_page_xpath)))
                    print(f"    - ë‹¤ìŒ í˜ì´ì§€({next_page})ë¡œ ì´ë™ ì‹œë„")
                    
                    # í˜ì´ì§€ ì´ë™ ì „ í˜„ì¬ URL ì €ì¥
                    before_url = driver.current_url
                    next_page_btn.click()
                    time.sleep(3)  # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸° ì‹œê°„ ì¦ê°€
                    
                    # í˜ì´ì§€ ì´ë™ í™•ì¸
                    after_url = driver.current_url
                    if before_url != after_url:
                        print(f"    - í˜ì´ì§€ ì´ë™ ì„±ê³µ: {before_url} â†’ {after_url}")
                        page_count = next_page
                        current_retry_count = 0  # ì„±ê³µì ìœ¼ë¡œ ì´ë™í–ˆìœ¼ë¯€ë¡œ ì¬ì‹œë„ ì¹´ìš´íŠ¸ ë¦¬ì…‹
                    else:
                        print(f"    - í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨: URLì´ ë³€ê²½ë˜ì§€ ì•ŠìŒ")
                        raise Exception("í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨")
                        
                except (NoSuchElementException, TimeoutException):
                    print("    - ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ. í˜ì´ì§€ë„¤ì´ì…˜ ë§ˆì§€ë§‰ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.")
                    break
                except Exception as e:
                    print(f"    - [ì—ëŸ¬] ë‹¤ìŒ í˜ì´ì§€ ì´ë™ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    break
                    
            except Exception as e:
                print(f"    - [ì—ëŸ¬] í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                break

print(f"ì´ {len(results)}ê°œ ìƒí’ˆ í¬ë¡¤ë§ ì™„ë£Œ")
driver.quit()